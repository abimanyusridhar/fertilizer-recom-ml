{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.82%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      1.00      0.92         6\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       1.00      0.50      0.67         4\n",
      "           4       0.50      0.50      0.50         2\n",
      "           5       0.83      1.00      0.91        15\n",
      "           6       0.57      0.67      0.62         6\n",
      "           7       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.82        44\n",
      "   macro avg       0.68      0.64      0.64        44\n",
      "weighted avg       0.82      0.82      0.81        44\n",
      "\n",
      "Model and encoders saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "file_path = 'fertilizer.csv'  # Update with the correct file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Encode categorical variables\n",
    "label_encoders = {}\n",
    "\n",
    "# Categorical columns (update based on your dataset)\n",
    "categorical_columns = ['Soil Type', 'Crop Type', 'Fertilizer Name']\n",
    "\n",
    "# Apply Label Encoding to categorical columns\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Save the Label Encoders for later use\n",
    "with open('label_encoders.pkl', 'wb') as le_file:\n",
    "    pickle.dump(label_encoders, le_file)\n",
    "\n",
    "# Step 3: Define features (X) and target (y)\n",
    "X = data.drop(columns=['Fertilizer Name'])  # Features (without target)\n",
    "y = data['Fertilizer Name']  # Target\n",
    "\n",
    "# Step 4: Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Identify numerical columns\n",
    "numeric_columns = ['Temparature', 'Humidity ', 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous']\n",
    "\n",
    "# Scale numerical columns\n",
    "X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "\n",
    "# Save the Scaler for future use\n",
    "with open('fertilizer_scaler.pkl', 'wb') as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n",
    "\n",
    "# Step 5: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Initialize the RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Step 7: Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 9: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 10: Save the trained model\n",
    "with open('fertilizer_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "print(\"Model and encoders saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'fertilizer.csv'  # Make sure the file path is correct\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "output_dir = 'static/images'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Distribution of Temperature\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['Temparature'], bins=30, kde=True)\n",
    "plt.title('Distribution of Temperature')\n",
    "plt.xlabel('Temperature (Â°C)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig(f'{output_dir}/temperature_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Distribution of Humidity\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['Humidity '], bins=30, kde=True)\n",
    "plt.title('Distribution of Humidity')\n",
    "plt.xlabel('Humidity (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig(f'{output_dir}/humidity_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Distribution of Nitrogen Levels\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['Nitrogen'], bins=30, kde=True)\n",
    "plt.title('Distribution of Nitrogen Levels')\n",
    "plt.xlabel('Nitrogen (ppm)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig(f'{output_dir}/nitrogen_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Select only numeric columns for the correlation heatmap\n",
    "numeric_data = data.select_dtypes(include=[float, int])\n",
    "\n",
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(numeric_data.corr(), annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.savefig(f'{output_dir}/correlation_heatmap_fertilizer.png')\n",
    "plt.close()\n",
    "\n",
    "# Bar chart of average Nitrogen levels by Soil Type\n",
    "plt.figure(figsize=(12, 6))\n",
    "average_nitrogen_by_soil = data.groupby('Soil Type')['Nitrogen'].mean().sort_values()\n",
    "sns.barplot(x=average_nitrogen_by_soil.index, y=average_nitrogen_by_soil.values)\n",
    "plt.title('Average Nitrogen Levels by Soil Type')\n",
    "plt.xlabel('Soil Type')\n",
    "plt.ylabel('Average Nitrogen (ppm)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(f'{output_dir}/average_nitrogen_by_soil.png')\n",
    "plt.close()\n",
    "\n",
    "# Bar chart of average Potassium levels by Crop Type\n",
    "plt.figure(figsize=(12, 6))\n",
    "average_potassium_by_crop = data.groupby('Crop Type')['Potassium'].mean().sort_values()\n",
    "sns.barplot(x=average_potassium_by_crop.index, y=average_potassium_by_crop.values)\n",
    "plt.title('Average Potassium Levels by Crop Type')\n",
    "plt.xlabel('Crop Type')\n",
    "plt.ylabel('Average Potassium (ppm)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(f'{output_dir}/average_potassium_by_crop.png')\n",
    "plt.close()\n",
    "\n",
    "# Pie chart of Fertilizer Distribution by Type\n",
    "plt.figure(figsize=(12, 8))\n",
    "fertilizer_distribution = data['Fertilizer Name'].value_counts()\n",
    "plt.pie(fertilizer_distribution, labels=fertilizer_distribution.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of Fertilizers by Type')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.savefig(f'{output_dir}/fertilizer_distribution.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and Evaluating Random Forest...\n",
      "Accuracy of Random Forest: 81.82%\n",
      "\n",
      "Classification Report for Random Forest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      1.00      0.92         6\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       1.00      0.50      0.67         4\n",
      "           4       0.50      0.50      0.50         2\n",
      "           5       0.83      1.00      0.91        15\n",
      "           6       0.57      0.67      0.62         6\n",
      "           7       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.82        44\n",
      "   macro avg       0.68      0.64      0.64        44\n",
      "weighted avg       0.82      0.82      0.81        44\n",
      "\n",
      "\n",
      "Training and Evaluating Logistic Regression...\n",
      "Accuracy of Logistic Regression: 72.73%\n",
      "\n",
      "Classification Report for Logistic Regression:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.83      0.77         6\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.67      1.00      0.80         2\n",
      "           5       0.87      0.87      0.87        15\n",
      "           6       0.44      0.67      0.53         6\n",
      "           7       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.73        44\n",
      "   macro avg       0.53      0.60      0.55        44\n",
      "weighted avg       0.71      0.73      0.71        44\n",
      "\n",
      "\n",
      "Training and Evaluating SVM...\n",
      "Accuracy of SVM: 70.45%\n",
      "\n",
      "Classification Report for SVM:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.67      0.80         6\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.50      1.00      0.67         2\n",
      "           5       0.87      0.87      0.87        15\n",
      "           6       0.44      0.67      0.53         6\n",
      "           7       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.70        44\n",
      "   macro avg       0.48      0.50      0.47        44\n",
      "weighted avg       0.74      0.70      0.71        44\n",
      "\n",
      "\n",
      "Training and Evaluating K-Nearest Neighbors...\n",
      "Accuracy of K-Nearest Neighbors: 65.91%\n",
      "\n",
      "Classification Report for K-Nearest Neighbors:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.75      0.50      0.60         6\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.67      0.50      0.57         4\n",
      "           4       0.25      0.50      0.33         2\n",
      "           5       0.75      0.80      0.77        15\n",
      "           6       0.50      0.67      0.57         6\n",
      "           7       0.88      0.70      0.78        10\n",
      "\n",
      "    accuracy                           0.66        44\n",
      "   macro avg       0.47      0.46      0.45        44\n",
      "weighted avg       0.70      0.66      0.67        44\n",
      "\n",
      "\n",
      "Training and Evaluating Naive Bayes...\n",
      "Accuracy of Naive Bayes: 68.18%\n",
      "\n",
      "Classification Report for Naive Bayes:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.83      0.91         6\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.29      1.00      0.44         2\n",
      "           5       0.93      0.87      0.90        15\n",
      "           6       0.38      0.50      0.43         6\n",
      "           7       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.68        44\n",
      "   macro avg       0.45      0.49      0.44        44\n",
      "weighted avg       0.74      0.68      0.70        44\n",
      "\n",
      "\n",
      "Training and Evaluating Decision Tree...\n",
      "Accuracy of Decision Tree: 61.36%\n",
      "\n",
      "Classification Report for Decision Tree:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.62      0.83      0.71         6\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.72      0.87      0.79        15\n",
      "           6       0.40      0.33      0.36         6\n",
      "           7       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.61        44\n",
      "   macro avg       0.34      0.34      0.34        44\n",
      "weighted avg       0.61      0.61      0.60        44\n",
      "\n",
      "\n",
      "Best Model: Random Forest saved successfully with accuracy: 81.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "file_path = 'fertilizer.csv'  # Update with the correct file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Encode categorical variables\n",
    "label_encoders = {}\n",
    "\n",
    "# Categorical columns (update based on your dataset)\n",
    "categorical_columns = ['Soil Type', 'Crop Type', 'Fertilizer Name']\n",
    "\n",
    "# Apply Label Encoding to categorical columns\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Save the Label Encoders for later use\n",
    "with open('samplelb.pkl', 'wb') as le_file:\n",
    "    pickle.dump(label_encoders, le_file)\n",
    "\n",
    "# Step 3: Define features (X) and target (y)\n",
    "X = data.drop(columns=['Fertilizer Name'])  # Features (without target)\n",
    "y = data['Fertilizer Name']  # Target\n",
    "\n",
    "# Step 4: Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Identify numerical columns\n",
    "numeric_columns = ['Temparature', 'Humidity ', 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous']\n",
    "\n",
    "# Scale numerical columns\n",
    "X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "\n",
    "# Save the Scaler for future use\n",
    "with open('samplescaler.pkl', 'wb') as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n",
    "\n",
    "# Step 5: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Initialize and Train different Classification Models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'SVM': SVC(kernel='linear', random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Dictionary to store the accuracy of each model\n",
    "model_accuracies = {}\n",
    "\n",
    "# Train each model and evaluate\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining and Evaluating {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    model_accuracies[model_name] = accuracy\n",
    "    \n",
    "    # Print accuracy and classification report\n",
    "    print(f'Accuracy of {model_name}: {accuracy * 100:.2f}%')\n",
    "    print(f\"\\nClassification Report for {model_name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 7: Save the best performing model\n",
    "best_model_name = max(model_accuracies, key=model_accuracies.get)\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "with open('best_fertilizer_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(best_model, model_file)\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name} saved successfully with accuracy: {model_accuracies[best_model_name] * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Model loaded successfully\n",
      "INFO:__main__:Scaler loaded successfully\n",
      "INFO:__main__:Label encoders loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5002\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [14/Sep/2024 12:13:15] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:__main__:Received data: {'features': ['Sandy', 'Maize', '26', '52', '38', '37', '0', '0']}\n",
      "INFO:__main__:Raw features: ['Sandy', 'Maize', '26', '52', '38', '37', '0', '0']\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "INFO:__main__:Prediction: [7]\n",
      "INFO:werkzeug:127.0.0.1 - - [14/Sep/2024 12:13:21] \"POST /predict HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/Sep/2024 12:14:10] \"GET /analytics HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/Sep/2024 12:14:10] \"\u001b[36mGET /static/images/temperature_distribution.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/Sep/2024 12:14:10] \"\u001b[36mGET /static/images/humidity_distribution.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/Sep/2024 12:14:10] \"\u001b[36mGET /static/images/nitrogen_distribution.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/Sep/2024 12:14:10] \"\u001b[36mGET /static/images/correlation_heatmap_fertilizer.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/Sep/2024 12:14:10] \"\u001b[36mGET /static/images/average_nitrogen_by_soil.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/Sep/2024 12:14:10] \"\u001b[36mGET /static/images/average_potassium_by_crop.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/Sep/2024 12:14:10] \"\u001b[36mGET /static/images/fertilizer_distribution.png HTTP/1.1\u001b[0m\" 304 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import pickle\n",
    "import numpy as np\n",
    "import logging\n",
    "from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load the trained model, scaler, and label encoders\n",
    "def load_artifacts():\n",
    "    try:\n",
    "        with open('fertilizer_model.pkl', 'rb') as model_file:\n",
    "            model = pickle.load(model_file)\n",
    "            app.logger.info(\"Model loaded successfully\")\n",
    "\n",
    "        with open('fertilizer_scaler.pkl', 'rb') as scaler_file:\n",
    "            scaler = pickle.load(scaler_file)\n",
    "            app.logger.info(\"Scaler loaded successfully\")\n",
    "\n",
    "        with open('label_encoders.pkl', 'rb') as le_file:\n",
    "            label_encoders = pickle.load(le_file)\n",
    "            app.logger.info(\"Label encoders loaded successfully\")\n",
    "            \n",
    "        return model, scaler, label_encoders\n",
    "    except Exception as e:\n",
    "        app.logger.error(f\"Error loading artifacts: {e}\")\n",
    "        raise e\n",
    "\n",
    "# Load artifacts\n",
    "model, scaler, label_encoders = load_artifacts()\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        app.logger.info('Received data: %s', data)\n",
    "\n",
    "        if not data or 'features' not in data:\n",
    "            raise ValueError(\"Invalid input data: 'features' key not found.\")\n",
    "\n",
    "        features = data['features']\n",
    "        app.logger.info('Raw features: %s', features)\n",
    "\n",
    "        if len(features) != 8:\n",
    "            raise ValueError(\"Invalid number of features provided.\")\n",
    "\n",
    "        # Extract and encode soil_type and crop_type (categorical features)\n",
    "        soil_type, crop_type = features[0], features[1]\n",
    "\n",
    "        if soil_type not in label_encoders['Soil Type'].classes_:\n",
    "            raise ValueError(f\"Soil Type '{soil_type}' not recognized.\")\n",
    "        if crop_type not in label_encoders['Crop Type'].classes_:\n",
    "            raise ValueError(f\"Crop Type '{crop_type}' not recognized.\")\n",
    "\n",
    "        soil_type_encoded = label_encoders['Soil Type'].transform([soil_type])[0]\n",
    "        crop_type_encoded = label_encoders['Crop Type'].transform([crop_type])[0]\n",
    "\n",
    "        # Extract numerical features\n",
    "        numerical_features = np.array(features[2:]).reshape(1, -1)\n",
    "\n",
    "        # Scale only the numerical features (Temperature, Humidity, etc.)\n",
    "        numerical_features_scaled = scaler.transform(numerical_features)\n",
    "\n",
    "        # Combine encoded categorical and scaled numerical features\n",
    "        final_features = np.concatenate([[soil_type_encoded, crop_type_encoded], numerical_features_scaled[0]])\n",
    "\n",
    "        # Predict using the model\n",
    "        prediction = model.predict([final_features])\n",
    "        app.logger.info('Prediction: %s', prediction)\n",
    "\n",
    "        fertilizer_recommendation = label_encoders['Fertilizer Name'].inverse_transform([int(prediction[0])])[0]\n",
    "\n",
    "        return jsonify({'recommendation': fertilizer_recommendation})\n",
    "    except ValueError as ve:\n",
    "        error_message = f\"Value Error: {str(ve)}\"\n",
    "        app.logger.error(error_message)\n",
    "        return jsonify({'error': error_message}), 400\n",
    "    except Exception as e:\n",
    "        error_message = f\"Error during prediction: {str(e)}\"\n",
    "        app.logger.error(error_message)\n",
    "        return jsonify({'error': error_message}), 500\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/analytics')\n",
    "def analytics():\n",
    "    return render_template('analytics.html')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=5002, use_reloader=False)  # Change port here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
